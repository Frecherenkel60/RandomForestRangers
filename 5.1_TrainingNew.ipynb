{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Rangers - Predicting Car Sales Prices\n",
    "## Training the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "# !pip install -q -r requirements.txt\n",
    "\n",
    "# On MacOS you need the following command\n",
    "# brew install libomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "def progress_bar(current, total, start_time, name, bar_width=30):\n",
    "    \"\"\"\n",
    "    Prints a progress bar to the shell.\n",
    "\n",
    "    Parameters:\n",
    "    - current (int): Current iteration.\n",
    "    - total (int): Total number of iterations.\n",
    "    - start_time (float): Start time of the process (from `time.time()`).\n",
    "    - name (string): Name of the run.\n",
    "    - bar_width (int): Width of the progress bar (default: 30).\n",
    "    \"\"\"\n",
    "    elapsed_time = time.time() - start_time\n",
    "    progress = current / total\n",
    "    completed = int(bar_width * progress)\n",
    "    remaining = bar_width - completed\n",
    "    progress_percent = int(progress * 100)\n",
    "    est_total_time = elapsed_time / progress if progress > 0 else 0\n",
    "    est_remaining_time = est_total_time - elapsed_time\n",
    "\n",
    "    # Create the progress bar\n",
    "    bar = f\"[{'#' * completed}{'-' * remaining}] {progress_percent}%\"\n",
    "\n",
    "    # Display current progress and ETA\n",
    "    sys.stdout.write(\n",
    "        f\"\\r{bar} ({current}/{total}) | Elapsed: {elapsed_time:.2f}s | ETA: {est_remaining_time:.2f}s / {name} \"\n",
    "    )\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Print a newline when done\n",
    "    if current == total:\n",
    "        sys.stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary modules\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_dataset_original = pd.read_csv('data/1_Preprocessing/train.csv')\n",
    "print(\"Training Dataset Original\")\n",
    "print(train_dataset_original.dtypes)\n",
    "print(train_dataset_original.head(10))\n",
    "print(50*'-')\n",
    "\n",
    "train_dataset_mixed = pd.read_csv('data/1_Preprocessing/train_generated_and_original.csv')\n",
    "print(\"Training Dataset Mixed\")\n",
    "print(train_dataset_mixed.dtypes)\n",
    "print(train_dataset_mixed.head(10))\n",
    "print(50*'-')\n",
    "\n",
    "test_dataset = pd.read_csv('data/1_Preprocessing/test.csv')\n",
    "print(\"Test Dataset\")\n",
    "print(test_dataset.dtypes)\n",
    "print(test_dataset.head(10))\n",
    "print(50*'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "X_train_original = train_dataset_original.drop(columns=['price'])\n",
    "y_train_original = train_dataset_original['price']\n",
    "\n",
    "X_train_mixed = train_dataset_mixed.drop(columns=['price'])\n",
    "y_train_mixed = train_dataset_mixed['price']\n",
    "\n",
    "X_test = test_dataset.drop(columns=['price'])\n",
    "y_test = test_dataset['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import product\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import RobustScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def adjusted_r2(r2, n, p):\n",
    "    \"\"\"Calculate Adjusted R².\"\"\"\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "def hyperparameter_tuning_with_cv(X, y, param_grid, model_class=LinearRegression, n_splits=5, random_state=42, verbose=True, polynomial=False, degree=2, name=\"Linear Regression\"):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning with K-Fold cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "    - X (DataFrame or ndarray): Feature matrix.\n",
    "    - y (Series or ndarray): Target vector.\n",
    "    - param_grid (dict): Hyperparameter grid as a dictionary of parameter lists.\n",
    "    - model_class (class): Model class to be instantiated (default: LinearRegression).\n",
    "    - n_splits (int): Number of splits for K-Fold cross-validation.\n",
    "    - random_state (int): Random state for reproducibility.\n",
    "    - verbose (bool): Activate verbose output.\n",
    "    - polynomial (bool): Whether to apply polynomial feature scaling on the dataset.\n",
    "    - degree (int): Degree of the polynomial features (default: 2).\n",
    "    - name (stirng): Name of the run (default: \"Linear Regression\").\n",
    "\n",
    "    Returns:\n",
    "    - dict: Best hyperparameters and performance metrics.\n",
    "    - list: All results for each hyperparameter combination.\n",
    "    \"\"\"\n",
    "    # Generate all combinations of hyperparameters\n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "    param_array = [dict(zip(param_grid.keys(), combo)) for combo in param_combinations]\n",
    "\n",
    "    # For tracking the progress in the shell\n",
    "    total_combinations = len(param_combinations)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Initialize variables to store results\n",
    "    results = []\n",
    "\n",
    "    # Scalers and transformers\n",
    "    scaler = RobustScaler()\n",
    "    poly_transformer = PolynomialFeatures(degree=degree, include_bias=False) if polynomial else None\n",
    "\n",
    "    # Iterate over all hyperparameter combinations\n",
    "    for index, params in enumerate(param_array, start=0):\n",
    "        if verbose:\n",
    "            print(f\"Testing hyperparameters: {params}\")\n",
    "        else:\n",
    "            progress_bar(index, total_combinations, start_time, name)\n",
    "\n",
    "        mae_scores = []\n",
    "        mape_scores = []\n",
    "        mse_scores = []\n",
    "        rmse_scores = []\n",
    "        adjusted_r2_scores = []\n",
    "        r2_scores = []\n",
    "        pcc_scores = []\n",
    "\n",
    "        # Perform K-Fold cross-validation\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            # Split the data\n",
    "            X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Apply polynomial feature transformation if specified\n",
    "            if polynomial:\n",
    "                X_train_fold = poly_transformer.fit_transform(X_train_fold)\n",
    "                X_test_fold = poly_transformer.transform(X_test_fold)\n",
    "\n",
    "            # Scale the data\n",
    "            X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "            X_test_fold = scaler.transform(X_test_fold)\n",
    "\n",
    "            # Create a new model for this fold with the current hyperparameters\n",
    "            model = model_class(**params)\n",
    "\n",
    "            # Fit the model\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            # Predict on the test fold\n",
    "            y_pred = model.predict(X_test_fold)\n",
    "\n",
    "            # Calculate metrics\n",
    "            mse = mean_squared_error(y_test_fold, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_test_fold, y_pred)\n",
    "            mape = mean_absolute_percentage_error(y_test_fold, y_pred)\n",
    "            r2 = max(0, r2_score(y_test_fold, y_pred)) # R² can be negative, make it 0 in this case\n",
    "            adj_r2 = max(0, adjusted_r2(r2, len(y_test_fold), X_test_fold.shape[1])) # R² can be negative, make it 0 in this case\n",
    "            pcc, _ = pearsonr(y_test_fold, y_pred)\n",
    "\n",
    "            # Store results for this fold\n",
    "            mse_scores.append(mse)\n",
    "            rmse_scores.append(rmse)\n",
    "            mae_scores.append(mae)\n",
    "            mape_scores.append(mape)\n",
    "            r2_scores.append(r2)\n",
    "            adjusted_r2_scores.append(adj_r2)\n",
    "            pcc_scores.append(pcc)\n",
    "\n",
    "        # Calculate mean metrics and store results\n",
    "        mean_mse = np.mean(mse_scores)\n",
    "        mean_rmse = np.mean(rmse_scores)\n",
    "        mean_mae = np.mean(mae_scores)\n",
    "        mean_mape = np.mean(mape_scores)\n",
    "        mean_r2 = np.mean(r2_scores)\n",
    "        mean_adj_r2 = np.mean(adjusted_r2_scores)\n",
    "        mean_pcc = np.mean(pcc_scores)\n",
    "\n",
    "        results.append({\n",
    "            'params': params,\n",
    "            'mean_mse': mean_mse,\n",
    "            'mean_rmse': mean_rmse,\n",
    "            'mean_mae': mean_mae,\n",
    "            'mean_mape': mean_mape,\n",
    "            'mean_r2': mean_r2,\n",
    "            'mean_adj_r2': mean_adj_r2,\n",
    "            'mean_pcc': mean_pcc\n",
    "        })\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Metrics for {params}:\")\n",
    "            print(f\"\\tMean RMSE: {mean_rmse:.4f}\")\n",
    "            print(f\"\\tMean MSE: {mean_mse:.4f}\")\n",
    "            print(f\"\\tMean MAE: {mean_mae:.4f}\")\n",
    "            print(f\"\\tMean MAPE: {mean_mape:.4f}\")\n",
    "            print(f\"\\tMean R²: {mean_r2:.4f}\")\n",
    "            print(f\"\\tMean Adjusted R²: {mean_adj_r2:.4f}\")\n",
    "            print(f\"\\tMean PCC: {mean_pcc:.4f}\")\n",
    "\n",
    "    if not verbose:\n",
    "        progress_bar(total_combinations, total_combinations, start_time, name)\n",
    "\n",
    "    # Select the best hyperparameters based on R²\n",
    "    best_result = max(results, key=lambda x: x['mean_r2'])\n",
    "    print(f\"\\nBest hyperparameters: {best_result['params']} with:\")\n",
    "    print(f\"\\tMean RMSE: {best_result['mean_rmse']:.4f}\")\n",
    "    print(f\"\\tMean MSE: {best_result['mean_mse']:.4f}\")\n",
    "    print(f\"\\tMean MAE: {best_result['mean_mae']:.4f}\")\n",
    "    print(f\"\\tMean MAPE: {best_result['mean_mape']:.4f}\")\n",
    "    print(f\"\\tMean R²: {best_result['mean_r2']:.4f}\")\n",
    "    print(f\"\\tMean Adjusted R²: {best_result['mean_adj_r2']:.4f}\")\n",
    "    print(f\"\\tMean PCC: {best_result['mean_pcc']:.4f}\")\n",
    "\n",
    "    return best_result, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualization\n",
    "def plot_results(y_true, y_pred):\n",
    "    # 1. Actual vs Predicted\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=y_true, y=y_pred, alpha=0.7, s=60)\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--', linewidth=2)\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title('Actual vs Predicted with Regression Line')\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Residuals\n",
    "    residuals = y_true - y_pred\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=y_pred, y=residuals, alpha=0.7)\n",
    "    plt.axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residual Plot')\n",
    "    plt.show()\n",
    "\n",
    "    # 3. Residual Histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(residuals, kde=True, bins=30, color='blue', alpha=0.7)\n",
    "    plt.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    plt.xlabel('Residuals')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Residuals')\n",
    "    plt.show()\n",
    "\n",
    "    # 4. Q-Q Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "    plt.title('Q-Q Plot of Residuals')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mileage_vs_price(mileage, actual_price, predicted_price, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Plots mileage vs. price with actual values, predicted values, and regression line/curve.\n",
    "\n",
    "    Args:\n",
    "    - mileage (array-like): Feature values (e.g., mileage).\n",
    "    - actual_price (array-like): Ground truth target values (e.g., price).\n",
    "    - predicted_price (array-like): Predicted target values from the model.\n",
    "    - model_name (str): Name of the model for the plot title.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Scatter plot for actual vs. predicted\n",
    "    plt.scatter(mileage, actual_price, color=\"blue\", label=\"Actual values\", alpha=0.6)\n",
    "    plt.scatter(mileage, predicted_price, color=\"red\", label=\"Predicted values\", alpha=0.6)\n",
    "\n",
    "    # Regression line/curve\n",
    "    sorted_indices = np.argsort(mileage)\n",
    "#    plt.plot(\n",
    " #       mileage[sorted_indices],\n",
    "  #      predicted_price[sorted_indices],\n",
    "   #     color=\"black\",\n",
    "    #    linestyle=\"--\",\n",
    "     #   linewidth=2,\n",
    "      #  label=\"Regression Line/Curve\"\n",
    "    #)\n",
    "\n",
    "    # Labeling\n",
    "    plt.title(f\"{model_name}: Mileage vs. Price\", fontsize=16)\n",
    "    plt.xlabel(\"Mileage\", fontsize=14)\n",
    "    plt.ylabel(\"Price\", fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "#################\n",
    "# Original data #\n",
    "#################\n",
    "\n",
    "best_result_linear_original, all_results_linear_original = hyperparameter_tuning_with_cv(X_train_original, y_train_original, param_grid, verbose=False, name=\"LR - Original\")\n",
    "\n",
    "best_params_linear_original = best_result_linear_original['params']\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_original_copy = X_train_original.copy()\n",
    "y_train_original_copy = y_train_original.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "y_test_copy = y_test.copy()\n",
    "\n",
    "X_train_scaled_original = scaler.fit_transform(X_train_original_copy)\n",
    "X_test_scaled_original = scaler.transform(X_test_copy)\n",
    "\n",
    "final_linear_model_original = LinearRegression(**best_params_linear_original)\n",
    "final_linear_model_original.fit(X_train_scaled_original, y_train_original_copy)\n",
    "\n",
    "# Generate predictions for evaluation\n",
    "y_pred_linear_original = final_linear_model_original.predict(X_test_scaled_original)\n",
    "plot_mileage_vs_price(\n",
    "    mileage=X_test['milage'],\n",
    "    actual_price=y_test,\n",
    "    predicted_price=y_pred_linear_original,\n",
    "    model_name=\"Linear Regression - Original\"\n",
    ")\n",
    "\n",
    "#################\n",
    "#   Mixed data  #\n",
    "#################\n",
    "\n",
    "best_result_linear_mixed, all_results_linear_mixed = hyperparameter_tuning_with_cv(X_train_mixed, y_train_mixed, param_grid, verbose=False, name=\"LR - Mixed\")\n",
    "best_params_linear_mixed = best_result_linear_mixed['params']\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_mixed_copy = X_train_mixed.copy()\n",
    "y_train_mixed_copy = y_train_mixed.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "y_test_copy = y_test.copy()\n",
    "\n",
    "X_train_scaled_mixed = scaler.fit_transform(X_train_mixed_copy)\n",
    "X_test_scaled_mixed = scaler.transform(X_test_copy)\n",
    "\n",
    "final_linear_model_mixed = LinearRegression(**best_params_linear_mixed)\n",
    "final_linear_model_mixed.fit(X_train_scaled_mixed, y_train_mixed_copy)\n",
    "\n",
    "# Generate predictions for evaluation\n",
    "y_pred_linear_mixed = final_linear_model_mixed.predict(X_test_scaled_original)\n",
    "plot_mileage_vs_price(\n",
    "    mileage=X_test['milage'],\n",
    "    actual_price=y_test,\n",
    "    predicted_price=y_pred_linear_mixed,\n",
    "    model_name=\"Linear Regression - Mixed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "#################\n",
    "# Original data #\n",
    "#################\n",
    "\n",
    "best_result_poly_original, all_results_poly_original = hyperparameter_tuning_with_cv(X_train_original, y_train_original, param_grid, polynomial=True, verbose=False, name=\"LR - Poly - Original\")\n",
    "best_params_poly_original = best_result_poly_original['params']\n",
    "\n",
    "scaler = RobustScaler()\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "X_train_original_copy = X_train_original.copy()\n",
    "y_train_original_copy = y_train_original.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "y_test_copy = y_test.copy()\n",
    "\n",
    "# Apply polynomial feature transformation\n",
    "X_train_poly = poly.fit_transform(X_train_original_copy)\n",
    "X_test_poly = poly.transform(X_test_copy)\n",
    "\n",
    "# Scale the polynomial features\n",
    "X_train_scaled_poly = scaler.fit_transform(X_train_poly)\n",
    "X_test_scaled_poly = scaler.transform(X_test_poly)\n",
    "\n",
    "final_model_poly_original = LinearRegression(**best_params_poly_original)\n",
    "final_model_poly_original.fit(X_train_scaled_original, y_train_original_copy)\n",
    "\n",
    "# Generate predictions for evaluation\n",
    "y_pred_poly_original = final_model_poly_original.predict(X_test_scaled_original)\n",
    "plot_mileage_vs_price(\n",
    "    mileage=X_test['milage'],\n",
    "    actual_price=y_test,\n",
    "    predicted_price=y_pred_poly_original,\n",
    "    model_name=\"Linear Regression with Poly - Original\"\n",
    ")\n",
    "\n",
    "#################\n",
    "#   Mixed data  #\n",
    "#################\n",
    "\n",
    "best_result_mixed, all_results_mixed = hyperparameter_tuning_with_cv(X_train_mixed, y_train_mixed, param_grid, polynomial=True, verbose=False, name=\"LR - Poly - Mixed\")\n",
    "\n",
    "best_params_poly_mixed = best_result_mixed['params']\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_mixed_copy = X_train_mixed.copy()\n",
    "y_train_mixed_copy = y_train_mixed.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "y_test_copy = y_test.copy()\n",
    "\n",
    "# Apply polynomial feature transformation\n",
    "X_train_poly = poly.fit_transform(X_train_mixed_copy)\n",
    "X_test_poly = poly.transform(X_test_copy)\n",
    "\n",
    "# Scale the polynomial features\n",
    "X_train_scaled_poly = scaler.fit_transform(X_train_poly)\n",
    "X_test_scaled_poly = scaler.transform(X_test_poly)\n",
    "\n",
    "final_model_poly_mixed = LinearRegression(**best_params_poly_mixed)\n",
    "final_model_poly_mixed.fit(X_train_scaled_mixed, y_train_mixed_copy)\n",
    "\n",
    "# Generate predictions for evaluation\n",
    "y_pred_poly_mixed = final_model_poly_mixed.predict(X_test_scaled_original)\n",
    "plot_mileage_vs_price(\n",
    "    mileage=X_test['milage'],\n",
    "    actual_price=y_test,\n",
    "    predicted_price=y_pred_poly_original,\n",
    "    model_name=\"Linear Regression with Poly - Mixed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 25, 50],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "#################\n",
    "# Original data #\n",
    "#################\n",
    "\n",
    "best_result_rfr_original, all_results_rfr_original = hyperparameter_tuning_with_cv(X=X_train_original, y=y_train_original, param_grid=param_grid, model_class=RandomForestRegressor, verbose=False)\n",
    "best_params_rfr_original = best_result_rfr_original['params']\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_original_copy = X_train_original.copy()\n",
    "y_train_original_copy = y_train_original.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "y_test_copy = y_test.copy()\n",
    "\n",
    "X_train_scaled_original = scaler.fit_transform(X_train_original_copy)\n",
    "X_test_scaled_original = scaler.transform(X_test_copy)\n",
    "final_model_rfr_original = RandomForestRegressor(**best_params_rfr_original)\n",
    "final_model_rfr_original.fit(X_train_scaled_original, y_train_original_copy)\n",
    "\n",
    "# Generate predictions for evaluation\n",
    "y_pred_rfr_original = final_model_rfr_original.predict(X_test_scaled_original)\n",
    "plot_mileage_vs_price(\n",
    "    mileage=X_test['milage'],\n",
    "    actual_price=y_test,\n",
    "    predicted_price=y_pred_rfr_original,\n",
    "    model_name=\"Random Forest Regressor - Original\"\n",
    ")\n",
    "\n",
    "#################\n",
    "#   Mixed data  #\n",
    "#################\n",
    "\n",
    "best_result_rfr_mixed, all_results_rfr_mixed = hyperparameter_tuning_with_cv(X=X_train_mixed, y=y_train_mixed, param_grid=param_grid, model_class=RandomForestRegressor, verbose=False)\n",
    "best_params_rfr_mixed = best_result_rfr_mixed['params']\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_mixed_copy = X_train_mixed.copy()\n",
    "y_train_mixed_copy = y_train_mixed.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "y_test_copy = y_test.copy()\n",
    "\n",
    "X_train_scaled_mixed = scaler.fit_transform(X_train_mixed_copy)\n",
    "X_test_scaled_mixed = scaler.transform(X_test_copy)\n",
    "\n",
    "final_model_rfr_original = RandomForestRegressor(**best_params_rfr_mixed)\n",
    "final_model_rfr_original.fit(X_train_scaled_mixed, y_train_mixed_copy)\n",
    "\n",
    "        # R² can be negative, this is equivalent to R² = 0\n",
    "        r2 = max(0, r2)\n",
    "\n",
    "        # Store results for this fold\n",
    "        mse_scores.append(mse)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "    # Calculate mean R² and store results\n",
    "    mean_r2 = np.mean(r2_scores)\n",
    "    results.append({'params': params, 'mean_r2': mean_r2})\n",
    "    if index % 100 == 0:\n",
    "        print(f\"Run {index} of {len}\")\n",
    "    index = index + 1\n",
    "\n",
    "# Train the final model with the best hyperparameters on the full dataset\n",
    "X_copy = X.copy()\n",
    "y_copy = y.copy()\n",
    "\n",
    "# Select the best hyperparameters\n",
    "best_result = max(results, key=lambda x: x['mean_r2'])\n",
    "best_params = best_result['params']\n",
    "print(f\"Best hyperparameters: {best_params} with Mean R²: {best_result['mean_r2']:.4f}\")\n",
    "\n",
    "# Train final model on the full dataset with the best hyperparameters\n",
    "final_model = RandomForestRegressor(**best_params)\n",
    "X_scaled = scaler.fit_transform(X_copy)\n",
    "final_model.fit(X_scaled, y_copy)\n",
    "\n",
    "# Predict on the full dataset\n",
    "y_pred_full = final_model.predict(X_scaled)\n",
    "# Generate predictions for evaluation\n",
    "y_pred_rfr_mixed = final_model_rfr_original.predict(X_test_scaled_original)\n",
    "plot_mileage_vs_price(\n",
    "    mileage=X_test['milage'],\n",
    "    actual_price=y_test,\n",
    "    predicted_price=y_pred_rfr_mixed,\n",
    "    model_name=\"Random Forest Regressor - Mixed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 25, 50, 100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.1, 0.3],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'min_child_weight': [1, 3]\n",
    "}\n",
    "\n",
    "#################\n",
    "# Original data #\n",
    "#################\n",
    "\n",
    "best_result_xg_original, all_results_xg_original = hyperparameter_tuning_with_cv(\n",
    "    X=X_train_original, y=y_train_original, param_grid=param_grid, model_class=XGBRegressor,\n",
    "    verbose=False, name=\"XGBoost - Original\"\n",
    ")\n",
    "best_params_xg_original = best_result_xg_original['params']\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_original_copy = X_train_original.copy()\n",
    "y_train_original_copy = y_train_original.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "y_test_copy = y_test.copy()\n",
    "\n",
    "X_train_scaled_original = scaler.fit_transform(X_train_original_copy)\n",
    "X_test_scaled_original = scaler.transform(X_test_copy)\n",
    "final_model_xg_original = XGBRegressor(**best_params_xg_original)\n",
    "final_model_xg_original.fit(X_train_scaled_original, y_train_original_copy)\n",
    "\n",
    "# Generate predictions for evaluation\n",
    "y_pred_xg_original = final_model_xg_original.predict(X_test_scaled_original)\n",
    "plot_mileage_vs_price(\n",
    "    mileage=X_test['milage'],\n",
    "    actual_price=y_test,\n",
    "    predicted_price=y_pred_xg_original,\n",
    "    model_name=\"XGBoost - Original\"\n",
    ")\n",
    "\n",
    "#################\n",
    "#   Mixed data  #\n",
    "#################\n",
    "\n",
    "best_result_xg_mixed, all_results_xg_mixed = hyperparameter_tuning_with_cv(\n",
    "    X=X_train_mixed, y=y_train_mixed, param_grid=param_grid,\n",
    "    model_class=XGBRegressor, verbose=False, name=\"XGBoost - Mixed\"\n",
    ")\n",
    "best_params_xg_mixed = best_result_xg_mixed['params']\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_mixed_copy = X_train_mixed.copy()\n",
    "y_train_mixed_copy = y_train_mixed.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "y_test_copy = y_test.copy()\n",
    "\n",
    "X_train_scaled_mixed = scaler.fit_transform(X_train_mixed_copy)\n",
    "X_test_scaled_mixed = scaler.transform(X_test_copy)\n",
    "final_model_xg_mixed = XGBRegressor(**best_params_xg_mixed)\n",
    "final_model_xg_mixed.fit(X_train_scaled_mixed, y_train_mixed_copy)\n",
    "\n",
    "# Generate predictions for evaluation\n",
    "y_pred_xg_mixed = final_model_xg_mixed.predict(X_test_scaled_original)\n",
    "plot_mileage_vs_price(\n",
    "    mileage=X_test['milage'],\n",
    "    actual_price=y_test,\n",
    "    predicted_price=y_pred_xg_mixed,\n",
    "    model_name=\"XGBoost - Mixed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "def training_XGBoost(initial_model, y, X):\n",
    "    # Cross-validation loop\n",
    "    mse_scores = []                     # Store MSE for each fold\n",
    "    r2_scores = []                      # Store R² for each fold\n",
    "    adjusted_r2_scores = []             # Store Adjusted R² for each fold\n",
    "    mean_absolute_percentage_error = [] # Store MAPE for each fold\n",
    "    mae_scores = []                     # Store MAE for each fold\n",
    "    model_list = []                     # Store the models for each fold\n",
    "\n",
    "    n = len(train_dataset_original)  # Total number of samples\n",
    "    p = X.shape[1]    # Number of predictors\n",
    "    i = 1\n",
    "\n",
    "    x_copy = X.copy()\n",
    "    y_copy = y.copy()\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        # Split the data\n",
    "        X_train_fold, X_val_fold = x_copy.iloc[train_index], x_copy.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_copy.iloc[train_index], y_copy.iloc[val_index]\n",
    "\n",
    "        # Make sure the model is reinitialized for each fold\n",
    "        model = None\n",
    "        model = initial_model\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Predict on the test fold\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "\n",
    "        # Calculate MSE\n",
    "        mse = mean_squared_error(y_val_fold, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "        # Calculate R²\n",
    "        r2 = r2_score(y_val_fold, y_pred)\n",
    "\n",
    "        # Negative R² is possible, however, this is equivalent to R² = 0\n",
    "        if r2 < 0:\n",
    "            r2 = 0\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "        # Calculate Adjusted R²\n",
    "        n_fold = len(y_val_fold)  # Number of samples in this fold\n",
    "        adjusted_r2 = 1 - ((1 - r2) * (n_fold - 1)) / (n_fold - p - 1)\n",
    "        adjusted_r2_scores.append(adjusted_r2)\n",
    "\n",
    "        # Calculate MAPE\n",
    "        mape = np.mean(np.abs((y_val_fold - y_pred) / y_val_fold)) * 100\n",
    "        mean_absolute_percentage_error.append(mape)\n",
    "\n",
    "        # Calculate MAE\n",
    "        mae = np.mean(np.abs(y_val_fold - y_pred))\n",
    "        mae_scores.append(mae)\n",
    "\n",
    "        print(f\"Run {i}:\\nMSE: {mse}\\nRMSE: {np.sqrt(mse)}\\nR2: {r2}\\nAdjusted R2: {adjusted_r2}\\n\")\n",
    "        i = i + 1\n",
    "\n",
    "        # Store the model\n",
    "        model_list.append(model)\n",
    "\n",
    "    dict_of_results = {\n",
    "        'mse': mse_scores,\n",
    "        'r2': r2_scores,\n",
    "        'adjusted_r2': adjusted_r2_scores,\n",
    "        'mape': mean_absolute_percentage_error,\n",
    "        'mae': mae_scores,\n",
    "        'model': model_list\n",
    "    }\n",
    "\n",
    "    return dict_of_results\n",
    "\n",
    "\n",
    "initial_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "results = training_XGBoost(initial_model, y_train_original, X_train_original)\n",
    "\n",
    "mse_scores = results['mse']\n",
    "r2_scores = results['r2']\n",
    "adjusted_r2_scores = results['adjusted_r2']\n",
    "mean_absolute_percentage_error = results['mape']\n",
    "mae_scores = results['mae']\n",
    "\n",
    "# Average metrics across folds\n",
    "avg_mse = sum(mse_scores) / len(mse_scores)\n",
    "avg_r2 = sum(r2_scores) / len(r2_scores)\n",
    "avg_adjusted_r2 = sum(adjusted_r2_scores) / len(adjusted_r2_scores)\n",
    "avg_mape = sum(mean_absolute_percentage_error) / len(mean_absolute_percentage_error)\n",
    "avg_mae = sum(mae_scores) / len(mae_scores)\n",
    "\n",
    "print(f\"Average MSE: {avg_mse:.2f}\")\n",
    "print(f\"Average R²: {avg_r2:.2f}\")\n",
    "print(f\"Average Adjusted R²: {avg_adjusted_r2:.2f}\")\n",
    "print(f\"Average MAPE: {avg_mape:.2f}\")\n",
    "print(f\"Average MAE: {avg_mae:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
