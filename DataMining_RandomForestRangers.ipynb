{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Frecherenkel60/RandomForestRangers/blob/main/DataMining_RandomForestRangers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Rangers - Predicting Car Sales Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTlcyvFcBIl7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = pd.read_csv('./data/used_car_prices_generated.csv')\n",
    "dataset = pd.read_csv('./data/used_car_prices_original.csv')\n",
    "\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Ensure consistent data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.copy()\n",
    "\n",
    "# Function to reformat numeric attributes with non-numeric elements such as currency symbols\n",
    "def reformat_non_numeric(text):\n",
    "    if not isinstance(text, object):\n",
    "        return float(text)\n",
    "    return float(re.sub(r'[^\\d.]', '', text))\n",
    "\n",
    "# Function to reformat the clean title column\n",
    "def reformat_clean_title(text):\n",
    "    return 1 if text == 'Yes' else 0\n",
    "\n",
    "# Function to reformat the accident column\n",
    "def reformat_accident(text):\n",
    "    return 0 if text == '' or text == 'None reported' else 1\n",
    "\n",
    "# Reformat the existing columns\n",
    "df['clean_title'] = df['clean_title'].apply(reformat_clean_title)\n",
    "df['price'] = df['price'].apply(reformat_non_numeric)\n",
    "df['milage'] = df['milage'].apply(reformat_non_numeric)\n",
    "df['accident'] = df['accident'].apply(reformat_accident)\n",
    "\n",
    "dataset = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.copy()\n",
    "\n",
    "# Function to extract number of cylinders\n",
    "def extract_cylinders(text):\n",
    "    match = re.search(r'(\\d+)\\s*Cylinder', text, re.IGNORECASE)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Function to extract horsepower\n",
    "def extract_hp(text):\n",
    "    match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*HP', text, re.IGNORECASE)\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "# Function to extract cubic capacity\n",
    "def extract_capacity(text):\n",
    "    match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*L', text, re.IGNORECASE)\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "# Function to extract whether the car has a turbo\n",
    "def extract_turbo(text):\n",
    "    match = re.search(r'Turbo', text, re.IGNORECASE)\n",
    "    return 1 if match else 0\n",
    "\n",
    "# Function to extract gear type\n",
    "def extract_gear_type(text):\n",
    "    match_automatic = re.search(r'Automatic|A/T', text, re.IGNORECASE)\n",
    "    match_manual = re.search(r'Manual|M/T', text, re.IGNORECASE)\n",
    "    return 'Automatic' if match_automatic else 'Manual' if match_manual else None\n",
    "\n",
    "# Function to extract the number of gears\n",
    "def extract_gears(text):\n",
    "    match = re.search(r'(\\d+)-Speed\\b', text, re.IGNORECASE)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Function to extract whether the car has dual shift\n",
    "def extract_dual_shift(text):\n",
    "    match = re.search(r'Dual Shift', text, re.IGNORECASE)\n",
    "    return 1 if match else 0\n",
    "\n",
    "# Apply the extraction functions to create new columns\n",
    "df['cylinders'] = df['engine'].apply(extract_cylinders)\n",
    "df['horsepower'] = df['engine'].apply(extract_hp)\n",
    "df['cubic_capacity'] = df['engine'].apply(extract_capacity)\n",
    "df['turbo'] = df['engine'].apply(extract_turbo)\n",
    "df['gear_type'] = df['transmission'].apply(extract_gear_type)\n",
    "df['gears'] = df['transmission'].apply(extract_gears)\n",
    "df['dual_shift'] = df['transmission'].apply(extract_dual_shift)\n",
    "\n",
    "dataset = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values per feature only print if there are any\n",
    "missing_values = dataset.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print('Missing values per feature:')\n",
    "if not missing_values.empty:\n",
    "    print(missing_values)\n",
    "\n",
    "# Fill in missing values with the median\n",
    "dataset['cylinders'] = dataset['cylinders'].fillna(dataset['cylinders'].median())\n",
    "dataset['horsepower'] = dataset['horsepower'].fillna(dataset['horsepower'].median())\n",
    "dataset['cubic_capacity'] = dataset['cubic_capacity'].fillna(dataset['cubic_capacity'].median())\n",
    "dataset['gears'] = dataset['gears'].fillna(dataset['gears'].median())\n",
    "\n",
    "# Fill in missing values with extra category\n",
    "dataset['gear_type'] = dataset['gear_type'].fillna('N/A')\n",
    "dataset['gear_type'] = dataset['gear_type'].fillna('N/A')\n",
    "\n",
    "# Print columns with data types\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some interesting plots and insights from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of car prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dataset['price'].dropna(), bins=100, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Car Prices')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot number of cars by brand\n",
    "plt.figure(figsize=(12, 8))\n",
    "dataset['brand'].value_counts().plot(kind='bar', color='green')\n",
    "plt.title('Number of Cars by Brand')\n",
    "plt.xlabel('Brand')\n",
    "plt.ylabel('Number of Cars')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot distribution of mileage\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dataset['milage'].dropna(), bins=100, color='red', edgecolor='black')\n",
    "plt.title('Distribution of Car Mileage')\n",
    "plt.xlabel('Mileage (mi)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for models\n",
    "dataset = dataset[[\n",
    "    'brand', \n",
    "    'model', \n",
    "    'model_year', \n",
    "    'milage', \n",
    "    'fuel_type', \n",
    "    'ext_col', \n",
    "    'int_col', \n",
    "    'accident', \n",
    "    'clean_title', \n",
    "    'cylinders', \n",
    "    'horsepower', \n",
    "    'cubic_capacity', \n",
    "    'turbo', \n",
    "    'gear_type', \n",
    "    'gears', \n",
    "    'dual_shift', \n",
    "    'price'\n",
    "]]\n",
    "# Encode categorical variables using label encoding\n",
    "label_encoders = {}\n",
    "for column in dataset.select_dtypes(include=['object']).columns:\n",
    "    label_encoders[column] = preprocessing.LabelEncoder()\n",
    "    dataset[column] = label_encoders[column].fit_transform(dataset[column])\n",
    "    dataset[column] = label_encoders[column].fit_transform(dataset[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Fold Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the features and target variable\n",
    "X = dataset.drop(columns=['price'])\n",
    "y = dataset['price']\n",
    "\n",
    "# Define the number of folds\n",
    "k = 5\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "print('X_train_fold shape:', X_train_fold.shape)\n",
    "print('X_test_fold shape:', X_test_fold.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Data structure to store the results\n",
    "benchmark_lr_models = []\n",
    "best_lr_model = None\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    lr_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions\n",
    "    y_lr_pred = lr_model.predict(X_test_fold)\n",
    "\n",
    "    # Calculate metrics\n",
    "    lr_mse = mean_squared_error(y_test_fold, y_lr_pred)\n",
    "    lr_r2 = r2_score(y_test_fold, y_lr_pred)\n",
    "\n",
    "    benchmark_lr_models.append({\n",
    "        'MSE': lr_mse,\n",
    "        'R2': lr_r2\n",
    "    })\n",
    "\n",
    "    if not best_lr_model or lr_mse < best_lr_model['MSE']:\n",
    "        best_lr_model = {\n",
    "            'model': lr_model,\n",
    "            'X_train': X_train_fold,\n",
    "            'X_test': X_test_fold,\n",
    "            'y_train': y_train_fold,\n",
    "            'y_test': y_test_fold,\n",
    "            'MSE': lr_mse,\n",
    "            'R2': lr_r2\n",
    "        }\n",
    "\n",
    "# Convert results to DataFrame\n",
    "benchmark_lr_models_df = pd.DataFrame(benchmark_lr_models)\n",
    "\n",
    "# round mean values to 2 decimal places\n",
    "print('Mean MSE :', round(benchmark_lr_models_df['MSE'].mean(), 2))\n",
    "print('Mean R2:', round(benchmark_lr_models_df['R2'].mean(), 2))\n",
    "\n",
    "print('Best model MSE:', round(best_lr_model['MSE'], 2))\n",
    "print('Best model R2:', round(best_lr_model['R2'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for the best model\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot actual test points\n",
    "plt.scatter(best_lr_model['y_test'], best_lr_model['y_test'], color='blue', alpha=0.5, label='Actual Prices')\n",
    "\n",
    "# Plot predicted points\n",
    "plt.scatter(best_lr_model['y_test'], best_lr_model['model'].predict(best_lr_model['X_test']), color='red', alpha=0.5, label='Predicted Prices')\n",
    "\n",
    "# Add a reference line\n",
    "plt.plot([best_lr_model['y_test'].min(), best_lr_model['y_test'].max()], [best_lr_model['y_test'].min(), best_lr_model['y_test'].max()], 'k--', lw=2)\n",
    "\n",
    "# Add a title and labels\n",
    "plt.title('Best Model: Actual vs Predicted Prices')\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Add a grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for mileage vs actual and predicted prices using the best linear regression model\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot actual prices\n",
    "plt.scatter(best_lr_model['X_test']['milage'], best_lr_model['y_test'], color='blue', alpha=0.5, label='Actual Prices')\n",
    "\n",
    "# Plot predicted prices\n",
    "plt.scatter(best_lr_model['X_test']['milage'], best_lr_model['model'].predict(best_lr_model['X_test']), color='red', alpha=0.5, label='Predicted Prices')\n",
    "\n",
    "# Add a title and labels\n",
    "plt.title('Mileage vs Actual and Predicted Prices (Linear Regression)')\n",
    "plt.xlabel('Mileage (mi)')\n",
    "plt.ylabel('Price ($)')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Add a grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Define the degree of the polynomial\n",
    "degree = 3\n",
    "\n",
    "# Initialize the polynomial features transformer\n",
    "poly = PolynomialFeatures(degree=degree)\n",
    "\n",
    "# Initialize the model\n",
    "poly_model = LinearRegression()\n",
    "\n",
    "# Data structure to store the results\n",
    "benchmark_poly_models = []\n",
    "best_poly_model = None\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Transform the features to polynomial features\n",
    "    X_train_poly = poly.fit_transform(X_train_fold)\n",
    "    X_test_poly = poly.transform(X_test_fold)\n",
    "\n",
    "    # Train the model\n",
    "    poly_model.fit(X_train_poly, y_train_fold)\n",
    "\n",
    "    # Make predictions\n",
    "    y_poly_pred = poly_model.predict(X_test_poly)\n",
    "\n",
    "    # Calculate metrics\n",
    "    poly_mse = mean_squared_error(y_test_fold, y_poly_pred)\n",
    "    poly_r2 = r2_score(y_test_fold, y_poly_pred)\n",
    "\n",
    "    benchmark_poly_models.append({\n",
    "        'MSE': poly_mse,\n",
    "        'R2': poly_r2\n",
    "    })\n",
    "\n",
    "    if not best_poly_model or poly_mse < best_poly_model['MSE']:\n",
    "        best_poly_model = {\n",
    "            'model': poly_model,\n",
    "            'X_train': X_train_fold,\n",
    "            'X_test': X_test_fold,\n",
    "            'y_train': y_train_fold,\n",
    "            'y_test': y_test_fold,\n",
    "            'MSE': poly_mse,\n",
    "            'R2': poly_r2\n",
    "        }\n",
    "\n",
    "# Convert results to DataFrame\n",
    "benchmark_poly_models_df = pd.DataFrame(benchmark_poly_models)\n",
    "\n",
    "# round mean values to 2 decimal places\n",
    "print('Mean MSE :', round(benchmark_poly_models_df['MSE'].mean(), 2))\n",
    "print('Mean R2:', round(benchmark_poly_models_df['R2'].mean(), 2))\n",
    "\n",
    "print('Best model MSE:', round(best_poly_model['MSE'], 2))\n",
    "print('Best model R2:', round(best_poly_model['R2'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for the best polynomial regression model\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot actual test points\n",
    "plt.scatter(best_poly_model['y_test'], best_poly_model['y_test'], color='blue', alpha=0.5, label='Actual Prices')\n",
    "\n",
    "# Plot predicted points\n",
    "plt.scatter(best_poly_model['y_test'], best_poly_model['model'].predict(poly.transform(best_poly_model['X_test'])), color='red', alpha=0.5, label='Predicted Prices')\n",
    "\n",
    "# Add a reference line\n",
    "plt.plot([best_poly_model['y_test'].min(), best_poly_model['y_test'].max()], [best_poly_model['y_test'].min(), best_poly_model['y_test'].max()], 'k--', lw=2)\n",
    "\n",
    "# Add a title and labels\n",
    "plt.title('Best Polynomial Regression Model: Actual vs Predicted Prices')\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Add a grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for mileage vs actual and predicted prices using the best polynomial regression model\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot actual prices\n",
    "plt.scatter(best_poly_model['X_test']['milage'], best_poly_model['y_test'], color='blue', alpha=0.5, label='Actual Prices')\n",
    "\n",
    "# Plot predicted prices\n",
    "plt.scatter(best_poly_model['X_test']['milage'], best_poly_model['model'].predict(poly.transform(best_poly_model['X_test'])), color='red', alpha=0.5, label='Predicted Prices')\n",
    "\n",
    "# Add a title and labels\n",
    "plt.title('Mileage vs Actual and Predicted Prices')\n",
    "plt.xlabel('Mileage (mi)')\n",
    "plt.ylabel('Price ($)')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Add a grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "randomforestrangers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
