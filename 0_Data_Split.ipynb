{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same folder --> folder data\n",
    "\n",
    "path_original = \"data/_Original/full_used_car_prices_original.csv\"\n",
    "path_generated = \"data/_Generated/full_used_car_prices_generated.csv\"\n",
    "\n",
    "data_original = pd.read_csv(path_original)\n",
    "data_generated = pd.read_csv(path_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generated.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation of the price column from $ to float in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original['price'] = data_original['price'].str.replace('$', '')\n",
    "data_original['price'] = data_original['price'].str.replace(',', '')\n",
    "data_original['price'] = data_original['price'].astype(int)\n",
    "data_original['price'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the test and train datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of the Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we would like to apply stratified sampling, we need to know the distribution of the target variable (for binning the continuous target variable). Since the target variable is heavily right-skewed (as seen in the histogram below), we will use log transformation to make it more normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target column\n",
    "y_original = data_original[\"price\"]\n",
    "\n",
    "# Use the log of the target column\n",
    "y_original_ln = np.log(y_original)\n",
    "print(max(y_original))\n",
    "print(max(y_original_ln))\n",
    "\n",
    "# Histogram of the target column\n",
    "plt.title('Distribution of Prices (skrewed)')\n",
    "plt.hist(y_original, bins=40)\n",
    "plt.xlabel('Price in $')\n",
    "plt.ylabel('Number of Cars')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of the ln target column\n",
    "plt.title('Distribution of Log Prices using log. transformation')\n",
    "plt.hist(y_original_ln, bins=40)\n",
    "plt.xlabel('Log of Price in $')\n",
    "plt.ylabel('Number of Cars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are some outliers in the target variable. We will take a look at the 20 most expensive cars in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the 10 largest values of the target column\n",
    "print(y_original.nlargest(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We agreed to remove the three samples with over 1 mio. USD in the target variable, since they are outliers and would distort the distribution greatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original_cleaned = y_original[y_original < 1000000]\n",
    "y_original_ln_cleaned = np.log(y_original_cleaned)\n",
    "plt.hist(y_original_cleaned, bins=40)\n",
    "plt.show()\n",
    "plt.hist(y_original_ln_cleaned, bins=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make 5 bins for the target variable, creating pseudo-classes in combination with the brand of the car for stratisfied sampling. This ensures that the test set is representative of the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new feature with the binning of the target column from ln\n",
    "y_binned = pd.cut(y_original_ln, bins=5, labels=False)\n",
    "\n",
    "# combine it with brand \n",
    "brand = data_original[\"brand\"]\n",
    "y_binned = y_binned.astype(str) + \"_\" + brand\n",
    "\n",
    "# Look at if there are classes with few samples\n",
    "print(\"Number of classes for sampling\", len(y_binned.value_counts()))\n",
    "print(len(y_binned.value_counts()[y_binned.value_counts() == 1]))\n",
    "y_binned.value_counts()[y_binned.value_counts() == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 24 pseudo-classes with only one sample (which would lead to problems in stratified sampling), we temporarly remove them and will distribute them randomly after the stratified sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# All the classes with only one sample should be in a separate set which will be splitted in the end usind random sampling\n",
    "X_single = data_original[y_binned.isin(y_binned.value_counts()[y_binned.value_counts() == 1].index)]\n",
    "\n",
    "# Sampling usind stratified sampling for the classes with more than one sample\n",
    "X = data_original.copy()[y_binned.isin(y_binned.value_counts()[y_binned.value_counts() > 1].index)]\n",
    "y_stratified = y_binned[y_binned.isin(y_binned.value_counts()[y_binned.value_counts() > 1].index)]\n",
    "\n",
    "# Stratified sampling usind y_binned 80% train and 20% test\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, stratify=y_stratified, random_state=42)\n",
    "\n",
    "# Distribute the single samples among the train and test set\n",
    "X_single_1, X_single_2 = train_test_split(X_single, test_size=0.2, random_state=42)\n",
    "X_train = pd.concat([X_train, X_single_1])\n",
    "X_test = pd.concat([X_test, X_single_2])\n",
    "\n",
    "# Plot histograms of the target column for the train and test set, using percentage instead of counts\n",
    "y_train = X_train[\"price\"]\n",
    "y_test = X_test[\"price\"]\n",
    "\n",
    "y_train_ln = np.log(y_train)\n",
    "y_test_ln = np.log(y_test)\n",
    "\n",
    "\n",
    "plt.hist(y_train_ln, bins=50, density=True, alpha=0.5, label=\"train\")\n",
    "plt.hist(y_test_ln, bins=50, density=True, alpha=0.5, label=\"test\")\n",
    "plt.xlabel(\"log(price) in $\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot ($$$) shows that the distribution of the target variable between the train and test set is close to similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the brand distribution in the train and test set\n",
    "brand_train = X_train[\"brand\"]\n",
    "brand_test = X_test[\"brand\"]\n",
    "\n",
    "df_brand = pd.DataFrame({\"train\": brand_train.value_counts(normalize=True), \"test\": brand_test.value_counts(normalize=True)})\n",
    "# Multiply by 100 to get percentage\n",
    "df_brand = df_brand * 100\n",
    "\n",
    "df_brand[\"diff\"] = df_brand[\"train\"] - df_brand[\"test\"]\n",
    "df_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print length of train and test set\n",
    "print(\"Length of train set:\", len(X_train))\n",
    "print(\"Length of test set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the brands should be sufficiently similar between the train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()\n",
    "\n",
    "# Save the train and test set\n",
    "X_train.to_csv(\"data/0_Data_Split/train.csv\", index=False)\n",
    "X_test.to_csv(\"data/0_Data_Split/test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "randomforestrangers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
